{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ca60a021",
      "metadata": {},
      "source": [
        "# NASA FIRMS Dataset\n",
        "\n",
        "Download at https://firms.modaps.eosdis.nasa.gov/download/."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fc8187b6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 14 file(s): ['fire_archive_SV-C2_2012.csv', 'fire_archive_SV-C2_2013.csv', 'fire_archive_SV-C2_2014.csv', 'fire_archive_SV-C2_2015.csv', 'fire_archive_SV-C2_2016.csv', 'fire_archive_SV-C2_2017.csv', 'fire_archive_SV-C2_2018.csv', 'fire_archive_SV-C2_2019.csv', 'fire_archive_SV-C2_2020.csv', 'fire_archive_SV-C2_2021.csv', 'fire_archive_SV-C2_2022.csv', 'fire_archive_SV-C2_2023.csv', 'fire_archive_SV-C2_2024.csv', 'fire_archive_SV-C2_2025.csv']\n",
            "Saved summary to: preprocessed/wildfire_count_by_year_type.csv\n",
            " year  type    count\n",
            " 2012     0 19503040\n",
            " 2012     1    20953\n",
            " 2012     2  1300566\n",
            " 2012     3   143892\n",
            " 2013     0 17875225\n",
            " 2013     1    23090\n",
            " 2013     2  1348256\n",
            " 2013     3   158075\n",
            " 2014     0 18847252\n",
            " 2014     1    27375\n",
            " 2014     2  1245267\n",
            " 2014     3   194652\n",
            " 2015     0 20026487\n",
            " 2015     1    30366\n",
            " 2015     2  1237209\n",
            " 2015     3   157695\n",
            " 2016     0 18899034\n",
            " 2016     1    28752\n",
            " 2016     2  1284168\n",
            " 2016     3   146176\n",
            " 2017     0 18583192\n",
            " 2017     1    28279\n",
            " 2017     2  1318994\n",
            " 2017     3   157048\n",
            " 2018     0 17676306\n",
            " 2018     1    20954\n",
            " 2018     2  1327777\n",
            " 2018     3   145156\n",
            " 2019     0 19605695\n",
            " 2019     1    18812\n",
            " 2019     2  1326206\n",
            " 2019     3   144437\n",
            " 2020     0 19322337\n",
            " 2020     1    18068\n",
            " 2020     2  1237285\n",
            " 2020     3   141628\n",
            " 2021     0 18887337\n",
            " 2021     1    16413\n",
            " 2021     2  1298250\n",
            " 2021     3   145758\n",
            " 2022     0 15907039\n",
            " 2022     1    21258\n",
            " 2022     2  1202734\n",
            " 2022     3   120815\n",
            " 2023     0 20368212\n",
            " 2023     1    21227\n",
            " 2023     2  1293068\n",
            " 2023     3   159521\n",
            " 2024     0 19720147\n",
            " 2024     1    15368\n",
            " 2024     2  1192204\n",
            " 2024     3   137140\n",
            " 2025     0 15054086\n",
            " 2025     1    29844\n",
            " 2025     2  1102942\n",
            " 2025     3   133358\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data_dir = os.path.abspath(\"wild_fire_nasa\")\n",
        "pattern = os.path.join(data_dir, \"fire_archive*.csv\")\n",
        "csv_files = sorted(glob.glob(pattern))\n",
        "\n",
        "if not csv_files:\n",
        "    print(f\"No fire_archive*.csv files found in {data_dir}\")\n",
        "\n",
        "print(f\"Found {len(csv_files)} file(s): {[os.path.basename(f) for f in csv_files]}\")\n",
        "\n",
        "# (year, type) -> count, process in chunks to save memory\n",
        "count_by_year_type = defaultdict(int)\n",
        "\n",
        "for filepath in csv_files:\n",
        "    for chunk in pd.read_csv(\n",
        "        filepath,\n",
        "        chunksize=100_000,\n",
        "        usecols=[\"acq_date\", \"type\"],\n",
        "    ):\n",
        "        chunk[\"year\"] = pd.to_datetime(chunk[\"acq_date\"], errors=\"coerce\").dt.year\n",
        "        chunk = chunk.dropna(subset=[\"year\"])\n",
        "        chunk[\"year\"] = chunk[\"year\"].astype(int)\n",
        "        for (year, typ), cnt in chunk.groupby([\"year\", \"type\"]).size().items():\n",
        "            count_by_year_type[(year, typ)] += cnt\n",
        "\n",
        "# Build summary DataFrame\n",
        "rows = [\n",
        "    {\"year\": year, \"type\": typ, \"count\": count}\n",
        "    for (year, typ), count in sorted(count_by_year_type.items())\n",
        "]\n",
        "summary = pd.DataFrame(rows)\n",
        "\n",
        "# Save long format (year, type, count)\n",
        "output_path = os.path.join(\"preprocessed\", \"wildfire_count_by_year_type.csv\")\n",
        "summary.to_csv(\"preprocessed/wildfire_count_by_year_type.csv\")\n",
        "print(f\"Saved summary to: {output_path}\")\n",
        "print(summary.to_string(index=False))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
